{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " TODO: \n",
    " \n",
    " - Step 1: Download data from ORCESTRA\n",
    " - Step 2: MultiAssayExperiment + BumpyMatrix deconstructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow.scripts.python.data.helpers import *\n",
    "import yaml\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables (?)\n",
    "RAW_DATA_PATH = f\"../../../rawdata/\"\n",
    "PROC_DATA_PATH = f\"../../../procdata/\"\n",
    "RESULTS_DATA_PATH = f\"../../../results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Set the dataset name for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset name\n",
    "# Should be in format \"RADCURE\" or \"Head-Neck-Radiomics-HN1\"\n",
    "# DATASET_NAME = \"Head-Neck-Radiomics-HN1\"\n",
    "# DATASET_NAME = \"HNSCC\"\n",
    "DATASET_NAME = \"RADCURE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step X: Load the config file for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = f\"../../config/{DATASET_NAME}.yaml\"\n",
    "config = yaml.safe_load(open(config_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step X: Pick imaging feature signatures to use\n",
    "This can be blank, or you can list the signatures from workflow/signatures/ that you want to use. The string must match the filename of the signature file exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIGNATURES = ['all_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step X: Make output directories for this pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make clinical procdata folder\n",
    "path_to_proc_clinical = os.path.join(PROC_DATA_PATH, DATASET_NAME, 'clinical')\n",
    "if not os.path.exists(path_to_proc_clinical):\n",
    "    os.makedirs(path_to_proc_clinical)\n",
    "\n",
    "# Make feature procdata folders\n",
    "data_sources = ['radiomics', 'deep_learning']\n",
    "data_types = ['clinical', 'features']\n",
    "\n",
    "for combo in itertools.product([DATASET_NAME], data_sources, data_types):\n",
    "    path_to_create = os.path.join(PROC_DATA_PATH, *combo)\n",
    "    \n",
    "    if not os.path.exists(path_to_create):\n",
    "        os.makedirs(path_to_create)\n",
    "\n",
    "# Optionally make train and test output folders\n",
    "if config[\"train_test_split\"][\"split\"] is True:\n",
    "    #### MAKE TRAIN AND TEST OUTPUT DIRECTORIES ####\n",
    "    split_data_types = ['clinical', 'train_features', 'test_features']\n",
    "    for combo in itertools.product([DATASET_NAME], data_sources, ['train_test_split'], split_data_types):\n",
    "        path_to_create = os.path.join(PROC_DATA_PATH, *combo)\n",
    "        \n",
    "        if not os.path.exists(path_to_create):\n",
    "            os.makedirs(path_to_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results data folder creation\n",
    "path_to_results_dataset = os.path.join(RESULTS_DATA_PATH, DATASET_NAME)\n",
    "\n",
    "if not os.path.exists(path_to_create):\n",
    "    os.makedirs(path_to_create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step X: Load clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical data loaded with 3346 patients.\n"
     ]
    }
   ],
   "source": [
    "clinical_data_path = os.path.join(RAW_DATA_PATH, DATASET_NAME, f\"clinical/{DATASET_NAME}.csv\")\n",
    "\n",
    "# Load clinical data into a pandas dataframe\n",
    "clinical_data = loadFileToDataFrame(clinical_data_path)\n",
    "print(f\"Clinical data loaded with {len(clinical_data)} patients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step X: Clean clinical data\n",
    "- Remove any specified exceptions in config file\n",
    "- Set up the outcome variable column by making sure it is a boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will exclude clinical variables: dict_keys(['Ds Site'])\n",
      "Clinical data updated, now has 3118 patients.\n"
     ]
    }
   ],
   "source": [
    "# Get exclusion variable dictionary from config file\n",
    "exclusion_clinical_variables = config[\"exclusion_variables\"]\n",
    "\n",
    "if exclusion_clinical_variables:\n",
    "    print(f\"Will exclude clinical variables: {exclusion_clinical_variables.keys()}\")\n",
    "    # Drop rows with values in the exclusion variables\n",
    "    clinical_data = subsetDataframe(clinical_data, excludeDict=exclusion_clinical_variables)\n",
    "    print(\"Clinical data updated, now has\", len(clinical_data), \"patients.\")\n",
    "else:\n",
    "    print(\"No exclusion variables found in config file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome Variable setup\n",
    "This data will be used for a Cox Proportional Hazards model, which expects time and event outcome variables. Time must be a continuous variable, and event must be a binary variable.\n",
    "Event Variable must be in the format where 1 is the event (e.g. death), and 0 is non-event (e.g. alive).\n",
    "In this pipeline, we are expecting the time to event to be in years, so will convert any other units to years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time column Length FU is numeric. Making copy with standardized column name.\n",
      "Event column Status is string. Checking what values are present in the column.\n",
      "Converting to binary where 0 is alive and 1 is dead.\n"
     ]
    }
   ],
   "source": [
    "# Set up ouptput variable columns for modelling\n",
    "time_column_label = config[\"outcome_variables\"][\"time_label\"]\n",
    "event_column_label = config[\"outcome_variables\"][\"event_label\"] \n",
    "\n",
    "# def survivalTimeColumnSetup\n",
    "# Confirm that time column is numeric\n",
    "if not np.issubdtype(clinical_data[time_column_label].dtype, np.number):\n",
    "    raise ValueError(f\"Time column {time_column_label} is not numeric. Please confirm time label in {DATASET_NAME}.yaml is the correct column or convert to numeric.\")\n",
    "else:\n",
    "    print(f\"Time column {time_column_label} is numeric. Making copy with standardized column name.\")\n",
    "    if config[\"outcome_variables\"][\"convert_to_years\"]:\n",
    "        print(f\"Converting time column {time_column_label} from days to years.\")\n",
    "        clinical_data[\"survival_time_in_years\"] = clinical_data[time_column_label] / 365\n",
    "    else:\n",
    "        clinical_data[\"survival_time_in_years\"] = clinical_data[time_column_label]\n",
    "\n",
    "\n",
    "# def survivalEventColumnSetup\n",
    "# Determine what type of value is in event column\n",
    "event_variable_type = type(clinical_data[event_column_label][0])\n",
    "if np.issubdtype(event_variable_type, np.number):\n",
    "    print(f\"Event column {event_column_label} is binary. Making copy with standardized column name.\")\n",
    "    clinical_data[\"survival_event_binary\"] = clinical_data[event_column_label]\n",
    "\n",
    "elif np.issubdtype(event_variable_type, np.bool_):\n",
    "    print(f\"Event column {event_column_label} is boolean. Converting to binary.\")\n",
    "    clinical_data[\"survival_event_binary\"] = clinical_data[event_column_label].astype(int)\n",
    "\n",
    "elif np.issubdtype(event_variable_type, np.str_):\n",
    "    print(f\"Event column {event_column_label} is string. Checking what values are present in the column.\")\n",
    "\n",
    "    event_column_values = clinical_data[event_column_label].str.lower().unique()\n",
    "\n",
    "    if len(event_column_values) != 2:\n",
    "        raise ValueError(f\"Event column {event_column_label} can only have two values. Please confirm event label in {DATASET_NAME}.yaml is the correct column or update to have only two values.\")\n",
    "    \n",
    "    # Check if alive and dead are present in the event column\n",
    "    if 'alive' in event_column_values and 'dead' in event_column_values: \n",
    "        print(f\"Converting to binary where 0 is alive and 1 is dead.\")\n",
    "\n",
    "        clinical_data['survival_event_binary'] = clinical_data[event_column_label].str.lower().replace({'alive': '0', 'dead': '1'}).astype(int)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Event column {event_column_label} doesn't contain any variation of 'alive' and 'dead'. Please confirm event label in {DATASET_NAME}.yaml is the correct column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set patient ID as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_patient_identifier = getPatientIdentifierLabel(clinical_data)\n",
    "clinical_data.set_index(clinical_patient_identifier, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save out cleaned and filtered clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_data.to_csv(os.path.join(PROC_DATA_PATH,DATASET_NAME,f\"clinical/cleaned_filtered_clinical_{DATASET_NAME}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step X: Get list of image types in each image feature folder\n",
    "Will be looping over each of these for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "readii_features_dir = os.path.join(RAW_DATA_PATH, DATASET_NAME, f\"readii_outputs\")\n",
    "fmcib_features_dir = os.path.join(RAW_DATA_PATH, DATASET_NAME, f\"fmcib_outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of image types in the radiomic and fmcib feature directories\n",
    "radiomic_image_types = sorted([file.removeprefix('radiomicfeatures_').removesuffix(\"_\" + DATASET_NAME + \".csv\") \n",
    "                        for file in os.listdir(readii_features_dir)])\n",
    "\n",
    "fmcib_image_types = sorted([file.removeprefix('fmcibfeatures_').removesuffix(\"_\" + DATASET_NAME + \".csv\") \n",
    "                           for file in os.listdir(fmcib_features_dir)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each image type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing radiomic features for original\n",
      "Radiomic data loaded with 5988 patients.\n",
      "Multiple patient identifier labels found. Using patient_ID.\n",
      "Patients with both clinical and radiomic features: 2920\n",
      "Number of segmentations with radiomic features: 2920\n",
      "Number of radiomic features: 1317\n",
      "Splitting clinical and radiomic features only data into training and test sets.\n",
      "Made copy of split variable with imputed columns: RADCURE-challenge_imputed\n",
      "Getting split for  RADCURE-challenge_imputed\n",
      "2207 training patients and 713 test patients.\n",
      "2207 training GTVs and 713 test GTVs.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Processing radiomic features for randomized_sampled_full\n",
      "Radiomic data loaded with 5988 patients.\n",
      "Multiple patient identifier labels found. Using patient_ID.\n",
      "Patients with both clinical and radiomic features: 2920\n",
      "Number of segmentations with radiomic features: 2920\n",
      "Number of radiomic features: 1317\n",
      "Splitting clinical and radiomic features only data into training and test sets.\n",
      "Made copy of split variable with imputed columns: RADCURE-challenge_imputed\n",
      "Getting split for  RADCURE-challenge_imputed\n",
      "2207 training patients and 713 test patients.\n",
      "2207 training GTVs and 713 test GTVs.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Processing radiomic features for randomized_sampled_non_roi\n",
      "Radiomic data loaded with 5988 patients.\n",
      "Multiple patient identifier labels found. Using patient_ID.\n",
      "Patients with both clinical and radiomic features: 2920\n",
      "Number of segmentations with radiomic features: 2920\n",
      "Number of radiomic features: 1317\n",
      "Splitting clinical and radiomic features only data into training and test sets.\n",
      "Made copy of split variable with imputed columns: RADCURE-challenge_imputed\n",
      "Getting split for  RADCURE-challenge_imputed\n",
      "2207 training patients and 713 test patients.\n",
      "2207 training GTVs and 713 test GTVs.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Processing radiomic features for randomized_sampled_roi\n",
      "Radiomic data loaded with 5988 patients.\n",
      "Multiple patient identifier labels found. Using patient_ID.\n",
      "Patients with both clinical and radiomic features: 2920\n",
      "Number of segmentations with radiomic features: 2920\n",
      "Number of radiomic features: 1317\n",
      "Splitting clinical and radiomic features only data into training and test sets.\n",
      "Made copy of split variable with imputed columns: RADCURE-challenge_imputed\n",
      "Getting split for  RADCURE-challenge_imputed\n",
      "2207 training patients and 713 test patients.\n",
      "2207 training GTVs and 713 test GTVs.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Processing radiomic features for shuffled_full\n",
      "Radiomic data loaded with 5988 patients.\n",
      "Multiple patient identifier labels found. Using patient_ID.\n",
      "Patients with both clinical and radiomic features: 2920\n",
      "Number of segmentations with radiomic features: 2920\n",
      "Number of radiomic features: 1317\n",
      "Splitting clinical and radiomic features only data into training and test sets.\n",
      "Made copy of split variable with imputed columns: RADCURE-challenge_imputed\n",
      "Getting split for  RADCURE-challenge_imputed\n",
      "2207 training patients and 713 test patients.\n",
      "2207 training GTVs and 713 test GTVs.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Processing radiomic features for shuffled_non_roi\n",
      "Radiomic data loaded with 5988 patients.\n",
      "Multiple patient identifier labels found. Using patient_ID.\n",
      "Patients with both clinical and radiomic features: 2920\n",
      "Number of segmentations with radiomic features: 2920\n",
      "Number of radiomic features: 1317\n",
      "Splitting clinical and radiomic features only data into training and test sets.\n",
      "Made copy of split variable with imputed columns: RADCURE-challenge_imputed\n",
      "Getting split for  RADCURE-challenge_imputed\n",
      "2207 training patients and 713 test patients.\n",
      "2207 training GTVs and 713 test GTVs.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Processing radiomic features for shuffled_roi\n",
      "Radiomic data loaded with 5988 patients.\n",
      "Multiple patient identifier labels found. Using patient_ID.\n",
      "Patients with both clinical and radiomic features: 2920\n",
      "Number of segmentations with radiomic features: 2920\n",
      "Number of radiomic features: 1317\n",
      "Splitting clinical and radiomic features only data into training and test sets.\n",
      "Made copy of split variable with imputed columns: RADCURE-challenge_imputed\n",
      "Getting split for  RADCURE-challenge_imputed\n",
      "2207 training patients and 713 test patients.\n",
      "2207 training GTVs and 713 test GTVs.\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "radiomics_procdata_path = os.path.join(PROC_DATA_PATH, DATASET_NAME, \"radiomics\")\n",
    "\n",
    "for image_type in radiomic_image_types:\n",
    "    print(f\"Processing radiomic features for {image_type}\")\n",
    "    # Load the feature data\n",
    "    readii_output_data = loadFileToDataFrame(f\"{readii_features_dir}/radiomicfeatures_{image_type}_{DATASET_NAME}.csv\")\n",
    "\n",
    "    print(f\"Radiomic data loaded with {len(readii_output_data)} patients.\")\n",
    "\n",
    "    # Set the patient ID as the index\n",
    "    radiomic_patient_identifier = getPatientIdentifierLabel(readii_output_data)\n",
    "\n",
    "    # Check data for duplicated rows and remove the second copy\n",
    "    readii_output_data = readii_output_data.drop_duplicates(subset=[radiomic_patient_identifier, \"series_UID\",\"image_modality\",\"seg_modality\",\"seg_ref_image\", \"roi\"])\n",
    "\n",
    "    readii_output_data.set_index(radiomic_patient_identifier, inplace=True)\n",
    "\n",
    "    ######### FIND COMMON PATIENTS #########\n",
    "    # Filter the clinical and image features to only include patients with imaging and clinical data based on image features index\n",
    "    # e.g. patients with only clinical data will not be included\n",
    "    common_patient_index = readii_output_data.index.intersection(clinical_data.index)\n",
    "    # Select just the common patients from clinical and image feature data\n",
    "    common_clinical_data = clinical_data.loc[common_patient_index]\n",
    "    common_readii_output_data = readii_output_data.loc[common_patient_index]\n",
    "    print(f\"Patients with both clinical and radiomic features: {len(common_clinical_data)}\")\n",
    "    print(f\"Number of segmentations with radiomic features: {len(common_readii_output_data)}\")\n",
    "\n",
    "    # Get just the radiomic feature columns from the dataframe, remove any metadata/diagnostics columns\n",
    "    radiomic_feats_only = getOnlyPyradiomicsFeatures(common_readii_output_data)\n",
    "    print(f\"Number of radiomic features: {(radiomic_feats_only.shape[1])}\")\n",
    "\n",
    "    ######### GET SURVIVAL OUTCOME LABELS #########\n",
    "    # Get the survival time and event columns\n",
    "    survival_labels = common_clinical_data[[\"survival_time_in_years\", \"survival_event_binary\"]]\n",
    "    surv_labelled_radiomic_feats = survival_labels.join(radiomic_feats_only)\n",
    "\n",
    "    # Save outputs at this point\n",
    "    common_clinical_data.to_csv(os.path.join(radiomics_procdata_path, f\"clinical/merged_clinical_{DATASET_NAME}.csv\"))\n",
    "    common_readii_output_data.to_csv(os.path.join(radiomics_procdata_path, f\"features/merged_radiomicfeatures_{image_type}_{DATASET_NAME}.csv\"))\n",
    "    # Save out labelled radiomic feature data\n",
    "    surv_labelled_radiomic_feats.to_csv(os.path.join(radiomics_procdata_path, f\"features/labelled_radiomicfeatures_only_{image_type}_{DATASET_NAME}.csv\"))\n",
    "\n",
    "\n",
    "    if config[\"train_test_split\"][\"split\"] is True:\n",
    "        print(\"Splitting clinical and radiomic features only data into training and test sets.\")\n",
    "        # Split the data into training and test sets\n",
    "        split_variable = config[\"train_test_split\"][\"split_variable\"]\n",
    "\n",
    "        # Check for rows of clinical dataframe that don't have a one of the values in the split variable dictionary\n",
    "        splitClinical, splitFeatures = splitDataSetup(common_clinical_data, surv_labelled_radiomic_feats, \n",
    "                                                        splitVariables = config[\"train_test_split\"][\"split_variable\"], \n",
    "                                                        imputeValue = config[\"train_test_split\"][\"impute\"])\n",
    "        \n",
    "        # Set up train test output path\n",
    "        train_test_dir = os.path.join(radiomics_procdata_path, \"train_test_split\")\n",
    "\n",
    "        # Save out training and test clinical data\n",
    "        splitClinical['training'].to_csv(os.path.join(train_test_dir, f\"clinical/train_merged_clinical_{DATASET_NAME}.csv\"))\n",
    "        splitClinical['test'].to_csv(os.path.join(train_test_dir, f\"clinical/test_merged_clinical_{DATASET_NAME}.csv\"))\n",
    "\n",
    "        # Save out training and test radiomic feature data\n",
    "        splitFeatures['training'].to_csv(os.path.join(train_test_dir, f\"train_features/train_labelled_radiomicfeatures_only_{image_type}_{DATASET_NAME}.csv\"))\n",
    "        splitFeatures['test'].to_csv(os.path.join(train_test_dir, f\"test_features/test_labelled_radiomicfeatures_only_{image_type}_{DATASET_NAME}.csv\"))\n",
    "\n",
    "        print(f\"{len(splitClinical['training'])} training patients and {len(splitClinical['test'])} test patients.\")\n",
    "        print(f\"{len(splitFeatures['training'])} training GTVs and {len(splitFeatures['test'])} test GTVs.\")\n",
    "        print(\"------------------------------------------------------------\")\n",
    "        print()\n",
    "\n",
    "    else:\n",
    "        print(\"No train test split specified in config file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "└── procdata\n",
    "    └── {DATASETNAME}\n",
    "        └──  all_features_data\n",
    "            └──  complete\n",
    "                ├── clinical\n",
    "                ├── readii\n",
    "                └── fmcib\n",
    "            └── train\n",
    "                ├── clinical\n",
    "                ├── readii\n",
    "                └── fmcib\n",
    "            └── test\n",
    "                ├── clinical\n",
    "                ├── readii\n",
    "                └── fmcib\n",
    "        └──  {signature_name}_data\n",
    "            └──  complete\n",
    "                ├── clinical\n",
    "                ├── readii\n",
    "                └── fmcib\n",
    "            └── train\n",
    "                ├── clinical\n",
    "                ├── readii\n",
    "                └── fmcib\n",
    "            └── test\n",
    "                ├── clinical\n",
    "                ├── readii\n",
    "                └── fmcib\n",
    "                    \n",
    "└── results\n",
    "    └── {DATASETNAME}\n",
    "        └── {signature_name}_model_results\n",
    "            ├── readii\n",
    "            └── fmcib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
